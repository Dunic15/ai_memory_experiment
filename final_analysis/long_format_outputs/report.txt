Long-format analyses (A–G)
Long source: Analysis long finals-.xlsx
Generated: 2026-01-05 14:03:34

A) Timing → learning outcomes (AI only)
- MCQ accuracy: Timing p < .001; Interaction p = 0.670
- Recall total score: Timing p = 0.983; Interaction p = 0.503
- Article-only accuracy: Timing p = 0.706; Interaction p = 0.608

B) Mechanism: ai_summary_accuracy → learning (AI only)
- MCQ accuracy: ai_summary_accuracy beta = 0.472, p < .001
- Recall total score: ai_summary_accuracy beta = 0.890, p = 0.259
- Article-only accuracy: ai_summary_accuracy beta = -0.134, p = 0.379
- Timing→MCQ shrink summary: saved `B2_timing_pairwise_base_vs_full_mcq_accuracy.csv` and model comparison

C) Structure → false lures (AI only)
- False-lure accuracy: Timing p = 0.380; Interaction p = 0.630
- false_lures_selected: saved base/mechanism mixed model fixed effects and structure-coefficient comparison

D) Effort/time as process variables (AI only)
- Mental effort: Timing p = 0.236; Interaction p = 0.111
- Summary time (sec): Timing p < .001; Interaction p = 0.717
- Summary time proportion: Timing p < .001; Interaction p = 0.879
- Reading time (min): Timing p = 0.324; Interaction p = 0.826
- Total time (sec): Timing p = 0.992; Interaction p = 0.745

E) AI trust/dependence (AI only)
- AI summary accuracy moderation by ai_trust: interaction p = 0.090
- AI summary accuracy moderation by ai_dependence: interaction p = 0.037
- AI summary accuracy moderation by prior_knowledge_familiarity: interaction p = 0.339
- MCQ accuracy moderation by ai_trust: interaction p = 0.008
- MCQ accuracy moderation by ai_dependence: interaction p = 0.313
- MCQ accuracy moderation by prior_knowledge_familiarity: interaction p = 0.521
E3) Group × prior knowledge (participant mean MCQ)
- Group×prior_knowledge interaction p = 0.858
E4) Time-on-task models (log-transformed due to skew)
- AI only: article_accuracy ~ log_reading_time p = 0.518

H) Recall-focused analyses (mixed models)
H1) MCQ accuracy ~ recall_total_score
- All participants: recall_total_score beta = -0.002, p = 0.838
- AI only (controls timing/structure): recall_total_score beta = 0.003, p = 0.706

H2) Recall total score predictors
- All participants: reading_time p = 0.705; effort p = 0.202; prior knowledge p = 0.257
- AI only: ai_summary_accuracy p = 0.822; summary_time p = 0.344; trust p = 0.150; dependence p = 0.161

H3) Recall confidence calibration models
- All participants: confidence p = 0.010; confidence×group p = 0.110
- AI only: confidence×trust p = 0.850
- AI only: confidence×dependence p = 0.457

I) Buffer / cue interpretation checks (AI only)
I0) Timing contrasts on AI summary accuracy (base vs +log(summary_time))
- log(summary_time) effect: beta = 0.066, p = 0.056
- Summary time -> summary accuracy: p = 0.068
- MCQ model: summary_time p = 0.367; ai_summary_accuracy p < .001; article_accuracy p < .001

F) Confidence calibration
- Correlation (all): r = 0.043, p = 0.660
- Overconfidence group t-test: p = 0.890

G) Article effects (robustness)
- MCQ: group×article interaction p = 0.573

